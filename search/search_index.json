{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"k8s demonstration","text":"<p>This repo demonstrates using Kubernetes (k8s) for some simple use cases. The main purpose, is to see how viable it is as an alternative for small scale projects.</p>"},{"location":"#goals","title":"Goals","text":"<p>Initial setup:</p> <ul> <li> Terraform setup for AKS (Azure Kubernetes Service) k8s cluster</li> <li> ArgoCD setup</li> <li> Argo Workflows managed by ArgoCD</li> <li> Pass large data to inference job</li> <li> Return large data from inference job</li> </ul> <p>Long term:</p> <ul> <li> Separate environments for dev, staging, and production</li> <li> Job with on-demand GPU node</li> </ul>"},{"location":"#getting-started","title":"Getting started","text":""},{"location":"#set-up-aks","title":"Set up AKS","text":"<p>To get started, set up the cluster, navigate to the <code>infrastructure/terraform</code> directory, and run the following commands:</p> <pre><code>terraform init\nterraform apply\n</code></pre> <p>Then, to get CLI access, run: <code>az aks get-credentials --resource-group k8s-demo-application --name aks-cluster</code>. See the Azure documentation for more details.</p> <p>Tip</p> <p>Run <code>source &lt;(kubectl completion zsh)</code> to enable command completion for <code>kubectl</code> in your terminal.</p>"},{"location":"#set-up-platform-helpers","title":"Set up platform / helpers","text":""},{"location":"#ingress-nginx","title":"Ingress Nginx","text":"<p>Navigate to <code>k8s/ingress-nginx</code> <pre><code>helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx\nhelm repo update\nhelm install ingress-nginx ingress-nginx/ingress-nginx \\\n    --namespace ingress-nginx --create-namespace -f values.yaml\n</code></pre></p>"},{"location":"#set-up-cert-manager","title":"Set up cert manager","text":"<p>Install cert manager <pre><code>helm install \\\n  cert-manager jetstack/cert-manager \\\n  --namespace cert-manager \\\n  --create-namespace \\\n  --set crds.enabled=true\n</code></pre> and create cluster issuers</p> <pre><code>kubectl apply -f production-issuer.yaml -f staging-issuer.yaml\n</code></pre>"},{"location":"#argocd","title":"ArgoCD","text":"<p>Then set up the ArgoCD (see more details in the official documentation)</p> <pre><code>IP=$(kubectl -n ingress-nginx get svc ingress-nginx-controller \\\n     -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\nDOMAIN=\"argocd.${IP}.sslip.io\"\nGRPC_DOMAIN=\"grpc.${DOMAIN}\"\n\nhelm upgrade --install argo argo/argo-cd \\\n  -n argocd --create-namespace \\\n  -f values.yaml \\\n  --set-string global.domain=\"$DOMAIN\" \\\n  --set-string \"server.ingress.hosts[0]=$DOMAIN\" \\\n  --set-string \"server.ingressGrpc.hosts[0]=$GRPC_DOMAIN\"\n</code></pre> <p>Getting credentials</p> <pre><code>argocd admin initial-password -n argocd\nargocd login &lt;ARGOCD_SERVER&gt;  # grpc.argocd.{IP}.sslip.io if set up as above\nargocd account update-password\n</code></pre>"},{"location":"#argo-workflows","title":"Argo Workflows","text":"<p>We'll now set up Argo Workflows:</p> <pre><code>kubectl apply -f k8s/argo-workflows/application.yaml -n argocd\n</code></pre>"},{"location":"#the-demo-application","title":"The Demo application","text":"<p>And we can now finally deploy the demo application:</p> <pre><code>kubectl apply -f k8s/demo/application.yaml\n</code></pre>"},{"location":"#good-resources","title":"Good resources","text":"<ul> <li>https://github.com/argoproj/argocd-example-apps/tree/master</li> <li>https://github.com/argoproj/argoproj-deployments/tree/master</li> <li>https://github.com/markti/terraform-hashitalks-2024/tree/main</li> <li>https://medium.com/@michael.cook.talk/argo-workflows-minio-nginx-8911b988b5c8</li> </ul>"},{"location":"lessons/","title":"Lessons learned / Challanges","text":""},{"location":"lessons/#setting-up-ingress-controller","title":"Setting up Ingress controller","text":"<p>The Azure stuff was very confusing. Tried using Nginx Ingress Controller, which was supposed to be simpler, but had some issues. As written in https://kubernetes.github.io/ingress-nginx/deploy/#quick-start, there might be issues with managed providers. So the recommendation is to run the cloud deploy manifest.</p> <p>https://cert-manager.io/docs/releases/release-notes/release-notes-1.18/ <pre><code>  config:\n    # Disable strict path validation, to work around a bug in ingress-nginx\n    # https://github.com/kubernetes/ingress-nginx/issues/11176\n    strict-validate-path-type: false\n</code></pre></p>"},{"location":"lessons/#nginx-ingress-vs-ingress-nginx","title":"Nginx-Ingress vs Ingress-Nginx","text":""},{"location":"lessons/#using-manged-identities","title":"Using manged identities","text":"<p>Info</p> <p>While using manged identities on AKS is in theory simple, I had some issues making it work. The documentation from Azure was somewhat confusing, and did not suggest good ways to test if it worked...</p> <p>Two things must be in place from the cluster side (in addition to setting federation up in Azure)</p> <ol> <li>The service account must have the correct client-id as an annotation</li> <li>The pod must have the label <code>azure.workload.identity/use=true</code></li> </ol> <p>Sometimes, even with this, things seemed to now work. I have not investigated thoroughly, but suspect either I set something wrong, or the order matters (like having the pod label during creating, not adding it after).</p>"},{"location":"demo_app/","title":"Overview","text":"<p>The sample app we are making, is a simple static front end. It allows the user to supply some input, which is handled by an API. The API starts a job, which requires a GPU node, which will be allocated on demand. The job will run a model inference, and return the result to the front end.</p> <p>The components we need, are:</p> <ul> <li>A static front end, served by a web server</li> <li>An API server to handle requests</li> <li>A job that runs a model inference using a GPU node</li> </ul> <p>In addition, we will use </p> <ul> <li>ArgoCD for continuous deployment</li> <li>Argo Workflows for managing the job execution</li> <li>Azure Kubernetes Service (AKS) for hosting the Kubernetes cluster and managing node pools</li> </ul>"},{"location":"demo_app/infrastructure/","title":"Infrastructure","text":"<p>The infrastructure is rather simple, and set up in Terraform. We use Azure Kubernetes Service (AKS) to host the Kubernetes cluster, and manage node pools. In addition, we have an Azure Stroage Account to store artifacts.</p>"},{"location":"demo_app/platform/","title":"Platform","text":"<p>One of the big advantages of Kubernetes, is the rich ecosystem of tools and services that can be deployed on and integrated with it. For this app, we leverage two tools from the Argo project: ArgoCD for continuous deployment, and Argo Workflows for managing the job execution.</p>"},{"location":"demo_app/platform/#argocd","title":"ArgoCD","text":"<p>ArgoCD is a tool for continuous deployment in Kubernetes. Whenever you push changes to a Git repository, ArgoCD will automatically deploy the changes to your Kubernetes cluster. It also has a web UI; the UI allows you to see the state of your application, and is a nice way to build some intuition with Kubernetes objects.</p>"},{"location":"demo_app/platform/#argo-workflows","title":"Argo Workflows","text":"<p>While it is possible to run jobs directly in Kubernetes, we use Argo Workflows to manage the job execution. Argo Workflows offer more flexible and advanced handling of jobs, such as retries, dependencies, and artifact management.</p>"},{"location":"demo_app/the_app/","title":"The App","text":""},{"location":"presentation/","title":"Presentation","text":"<p>Here are some instructions for what to set up (by the admin) on the presentation day.</p>"},{"location":"presentation/#auth-for-the-dashboard","title":"Auth for the dashboard","text":"<p>Create a namespace and service account, give it appropriate role, and create a token:</p> <pre><code># choose a dedicated namespace (keeps things tidy)\nkubectl create ns demo-access\n\n# service account\nkubectl -n demo-access create sa demo-admin\n\n# cluster-wide superuser (be careful!)\ncat &lt;&lt;'EOF' | kubectl apply -f -\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: demo-admin-cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: demo-admin\n  namespace: demo-access\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nEOF\n\n# short-lived token (e.g., 24h). Run again to refresh whenever you want.\nkubectl -n demo-access create token demo-admin --duration=24h\n</code></pre>"},{"location":"presentation/#auth-for-kubectl","title":"Auth for <code>kubectl</code>","text":"<p>Assuming the service account above is already created, do</p> <p><pre><code>SERVER=$(kubectl config view --raw -o jsonpath='{.clusters[0].cluster.server}')\nCA_DATA=$(kubectl config view --raw -o jsonpath='{.clusters[0].cluster.certificate-authority-data}')\nTOKEN=$(kubectl -n demo-access create token demo-admin --duration=24h)\n\ncat &gt; ./demo-admin.kubeconfig &lt;&lt;EOF\napiVersion: v1\nkind: Config\nclusters:\n- name: demo-aks\n  cluster:\n    server: ${SERVER}\n    certificate-authority-data: ${CA_DATA}\nusers:\n- name: demo-admin\n  user:\n    token: ${TOKEN}\ncontexts:\n- name: demo-admin@demo-aks\n  context:\n    cluster: demo-aks\n    user: demo-admin\ncurrent-context: demo-admin@demo-aks\nEOF\necho \"Wrote ./demo-admin.kubeconfig\"\n</code></pre> and have uers use the <code>demo-admin.kubeconfig</code> as their config file, by doing <code>export KUBECONFIG=./demo-admin.kubeconfig</code>.</p>"},{"location":"presentation/#ingress-for-grafana","title":"Ingress for Grafana","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: grafana-ingress\n  namespace: monitoring\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-production\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - grafana.4.210.9.109.sslip.io\n    secretName: grafana-ingress-tls\n  rules:\n  - host: grafana.4.210.9.109.sslip.io\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: kube-prometheus-stack-grafana\n            port:\n              name: http-web\n</code></pre>"},{"location":"presentation/copy-paste/","title":"Copy-Paste","text":"<p>Info</p> <p>Here are some snippets for simple copy-paste.</p>"},{"location":"presentation/copy-paste/#simple-example","title":"Simple example","text":"<p>Warning</p> <p>For simplicity, we did not include any namespace in the manifests. You should add this explicitly as a flag, like <code>kubectl apply -f &lt;file&gt; --namespace my-namespace</code>.</p> <p>To run a simple nginx demo web server, we start a pod like <pre><code># pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-web\n  labels:\n    app: hello-web\nspec:\n  containers:\n    - name: hello-web\n      image: nginxdemos/hello:plain-text\n      ports:\n        - containerPort: 80\n</code></pre></p> <code>deployment.yaml</code><code>service.yaml</code> <p><pre><code># deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-web\n  labels:\n    app: hello-web\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hello-web\n  template:\n    metadata:\n      labels:\n        app: hello-web\n    spec:\n      containers:\n        - name: hello-web\n          image: nginxdemos/hello:plain-text\n          ports:\n            - containerPort: 80\n</code></pre> <p>Notice how the highlighted section in the deployment, is exactly the same as the pod spec!</p> <pre><code># service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: hello-web\nspec:\n  selector:\n    app: hello-web\n  ports:\n    - port: 80\n      targetPort: 80\n      protocol: TCP\n</code></pre> Exposing publicly! <p>To expose our service outside the cluster, we'll make an ingress. <pre><code># ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: hello-web\nspec:\n  ingressClassName: nginx\n  rules:\n    - host: demo-ingress.&lt;yourname&gt;.&lt;IP&gt;.sslip.io\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: hello-web\n                port:\n                  number: 80\n</code></pre></p>"},{"location":"presentation/exercises/","title":"Exercises","text":"<p>Tip</p> <p>Remember to activate completions!</p> <pre><code>source &lt;(kubectl completion zsh)  # Modify as appropriate for other shells\n</code></pre>"},{"location":"presentation/exercises/#verify-access-to-cluster","title":"Verify access to cluster","text":"<p>To verify we have access to the cluster, we'll run</p> <pre><code>kubectl cluster-info\n</code></pre>   which should result in something like  <pre><code>Kubernetes control plane is running at https://xxx:443\nCoreDNS is running at https://xxx:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\nMetrics-server is running at https://xxx:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\n</code></pre> <p>and</p> <p><pre><code>kubectl get namespaces\n</code></pre> which should list some namespaces.</p>"},{"location":"presentation/exercises/#create-a-pod-running-a-demo-web-server","title":"Create a pod running a demo web server","text":"<p>First, well create a namespace for ourselves:</p> <pre><code>kubectl create namespace &lt;yourname&gt;\n</code></pre> <p>We now create a pod in our namespace</p> <p>Note the <code>---namespace &lt;yourname&gt;</code></p> <p><code>kubectl apply --namespace &lt;yourname&gt; -f pod.yaml</code> with <pre><code># pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-web\n  labels:\n    app: hello-web\nspec:\n  containers:\n    - name: hello-web\n      image: nginxdemos/hello:plain-text\n      ports:\n        - containerPort: 80\n</code></pre></p> <p>This will run a pod, which we can verify by <code>kubectl get pod --namespace &lt;yourname&gt;</code>, and you'll see something like <pre><code>NAME        READY   STATUS    RESTARTS   AGE\nhello-web   1/1     Running   0          13s\n</code></pre></p> <p>Setting default namespace</p> <p>To avoid typing <code>--namespace &lt;yourname&gt;</code> all the time, you can run <pre><code>kubectl config set-context --current --namespace=&lt;yourname&gt;\n</code></pre></p>"},{"location":"presentation/exercises/#access-the-web-server","title":"Access the web server","text":"<p>To access the web server, we need to expose it, meaning, createing a service for it. While we would normally do this with a YAML manifest (which we will see later), for now, create one with the <code>kubectl expose</code> command. If you did it correctly, you should now see something like this when listing services <pre><code>kubectl get services\nNAME        TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE\nhello-web   ClusterIP   10.0.251.230   &lt;none&gt;        80/TCP    5s\n</code></pre></p> <p>Alternative names and abbreviations</p> <p>In guides or when using the autocomplete, sometimes you will see different words used for the same thing. For example, services are sometimes abbreviated svc, as <code>kubectl get svc</code>. Deployments will sometimes be written as <code>deployments.apps</code>, etc.</p> <p>However, even though it is now exposed, we still have no way of visiting the endpoint! The service only makes the pod accessible internally on the cluster. To access it from our machines, it must be exposed externally. Later, we'll look at ingress, but for now, we'll simply port-forward the service: <pre><code>kubectl --namespace &lt;yourname&gt; port-forward services/hello-web 8080:80\n</code></pre> and visit it at http://localhost:8080.</p>"},{"location":"presentation/exercises/#a-better-way-with-deployments-and-services","title":"A better way with Deployments and Services","text":"<p>What we have made until now, has been more of a toy example. In reality, one rarely create pods manually, but rather deployments.</p>"},{"location":"presentation/exercises/#clean-up","title":"Clean up","text":"<p>First, clean up what we already made. One could simply delete the entire namespace, but try instead to find all resources in the namespace, and delete them one by one, using commands like</p> <ul> <li><code>kubectl get</code></li> <li><code>kubectl describe</code></li> <li><code>kubectl delete</code></li> </ul>"},{"location":"presentation/exercises/#making-our-deployment-and-service","title":"Making our deployment and service","text":"<p>Namespace</p> <p>For brevity, we here omit the namespace argument. Make sure to either include it, set the current context, or add it to the manifest YAML files!</p> <p>Copy the <code>deployment.yaml</code> and <code>service.yaml</code> from the copy-paste page, and apply them.</p> <p>Tip</p> <p>If you want, you can have all resource definitions in the same <code>.yaml</code> file, separated with a <code>---</code>. However, it is common to separate it into files, for more granular apply/delete control and better organization.</p> <p>Verify that there is a deployment and service in the namespace, and run <code>kubectl describe</code> on the deployment and corresponding replicaset. Check with <code>kubectl get</code> that the pods are created and ready.</p> Convenience heredocs <p>To avoid creating tons of files for simple operations, heredocs can be convenient. Simply do <pre><code>kubectl apply -f - &lt;&lt;EOF\n# pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-web\n  labels:\n    app: hello-web\nspec:\n  containers:\n    - name: hello-web\n      image: nginxdemos/hello:plain-text\n      ports:\n        - containerPort: 80\nEOF\n</code></pre></p>"},{"location":"presentation/exercises/#exposing-our-app-externally","title":"Exposing our app externally","text":"<p>There are several ways to expose apps externally. They all have different strengths and weaknesses; the interested reader can search for service types, and look at ClusterIP, NodePort, and LoadBalancer.</p> <p>On our cluster, which is quite normal, we have an ingress controller, allowing us to set up ingresses. An ingress is essentially a proxy server, that takes many requests coming to the same public IP, and directing them to the appropriate internal service.</p> <p>Ingresses are, as everything else in Kubernetes, set up usinga YAML manifest:</p> <pre><code># ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: hello-web\nspec:\n  ingressClassName: nginx\n  rules:\n    - host: demo-ingress.&lt;yourname&gt;.&lt;IP&gt;.sslip.io\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: hello-web\n                port:\n                  number: 80\n</code></pre> <p>In the above example, we do a small trick. Since we have no domain name pointing to our cluster yet, we use <code>sslip.io</code> as a DNS. It simply resolves the IP address in front of <code>sslip.io</code>.</p> <p>The IP address we put here, is the same as the one we would put into a domain name if we had one. To find it, we need to find the public IP address of our ingress controller's load balancer<sup>1</sup>.</p> <p>How to find this, is an exercise for the reader. Firstly, find the apprpriate namespace; its name involves <code>ingress</code> and <code>nginx</code>. Then, find a service of type <code>LoadBalancer</code>. That load balancer's IP address, is the one to use.</p> <p>Warning</p> <p>You are now looking into namespaces containing important internals of the cluster. If you have liberal permissions, thread carefully! <code>kubectl get</code> and <code>kubectl describe</code> is always safe, but do not use modifying commands.</p> <p>Now, you can visit your app at <code>demo-ingress.&lt;yourname&gt;.&lt;IP&gt;.sslip.io</code>.</p>"},{"location":"presentation/exercises/#clean-up_1","title":"Clean up","text":"<p>When you are finished, clean up everything by deleting your namespace.</p> <ol> <li> <p>If you did not understand that mouthful, don't worry!\u00a0\u21a9</p> </li> </ol>"},{"location":"what_is_k8s/","title":"What is Kubernetes?","text":"<p>While the Kubernetes docs are a great resource, we here present a brief overview of the most important concepts in Kubernetes for our application.</p> <p>Kubernetes is platform for running (Docker) containers. The platform lives on one or more machines, and intelligently handles running your containers where there is sufficient resources, managing their lifecycle, allowing you to read logs, and more.</p>"},{"location":"what_is_k8s/#components","title":"Components","text":"<p>When getting started, the most confusing part is the terminology, and the different levels of abstraction introduced. For example, you have:</p> <ul> <li>Containers</li> <li>Pods</li> <li>Replica sets</li> <li>Deployments</li> <li>Services</li> </ul> <p>The fundamental component in Kubernetes is the Pod. Where a container is the smallest unit when running things in Docker or Docker Compose, a Pod is the smallest unit in Kubernetes. A Pod contains one or more containers; however, for most simple use cases, it will only contain one, and you may think of a Pod as a single container.</p> <p>However, one very rarely run pods directly. Much of the power of Kubernetes comes from the higher level abstractions, such as Deployments and Services.</p> <p></p>"},{"location":"what_is_k8s/#deployments","title":"Deployments","text":"<p>A Deployment is the most common way to deploy an application to Kubernetes. A deployment declares a desired state for your application, such as which container image to run, how many replicas to run, and so on. Kubernetes then takes the necessary steps, such as creating replica sets, pods, etc, to ensure that the actual state matches the desired state.</p> <p>While the declaration of a deployment may seem very complex, all the parts are actually quite simple, and once you get started, declaring them becomes straightforward.</p> <pre><code># nginx-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n</code></pre>"},{"location":"what_is_k8s/#services","title":"Services","text":"<p>When running an application, we often want to expose it, either to the outside world, or to other applications running in the same Kubernetes cluster. Unlike Docker Compose, it is not enough to just expose a container port, like the <code>containerPort: 80</code> in the example above. We must also create a logical abstraction, called a Service, that allows the pod(s) to be reached.</p> <p>In simple terms, a Service is a way to group pods together and expose them under a single name. For example, if we run three pods (replicas) like the nginx deployment above, we can create a service that allows us to reach all three pods under the name <code>nginx-service</code>. Since all pods (replicas) are expected to run the same application, the inbound traffic will load balance requests between them.</p> <pre><code># nginx-service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-nginx\n  labels:\n    run: my-nginx\nspec:\n  ports:\n  - port: 80\n    protocol: TCP\n  selector:\n    run: my-nginx\n</code></pre>"},{"location":"what_is_k8s/working_with_k8s/","title":"Working with Kubernetes","text":"<p>While we recommend reading the official Kubernetes documentation, we here give a brief overview of how to work with Kubernetes.</p>"},{"location":"what_is_k8s/working_with_k8s/#fundamental-cli","title":"Fundamental CLI","text":"<p>Tip</p> <p>The <code>kubectl</code> command provides very good command line completions. You can enable them by running: <pre><code>source &lt;(kubectl completion YOUR_SHELL)\n</code></pre> where <code>YOUR_SHELL</code> is <code>bash</code>, <code>zsh</code>, <code>fish</code>, etc.</p> <p><code>kubectl</code> is the command line tool for interacting with Kubernetes. It has a consistent syntax which lets you create, update, delete, and inspect various Kubernetes objects. For example, to create a deployment, you can use:</p> <p>See this section of the docs for more details about the below examples.</p> <pre><code># Create a deployment named \"kubernetes-bootcamp\" using the specified image\nkubectl create deployment kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1\n\n# Get a list of all deployments\nkubectl get deployments\n\n# Get detailed information about all pods\nkubectl describe pods\n\n# Expose the deployment as a service, making it accessible from outside the cluster\nkubectl expose deployment/kubernetes-bootcamp --type=\"NodePort\" --port 8080\n\n# Delete the deployment and service\nkubectl delete deployments/kubernetes-bootcamp services/kubernetes-bootcamp\n</code></pre>"},{"location":"what_is_k8s/working_with_k8s/#working-with-yaml","title":"Working with YAML","text":"<p>Normally, we do not use <code>kubectl</code> to create objects directly. Instead, we define our objects in YAML files, and then use <code>kubectl apply</code> to create or update them. This allows us to version control our Kubernetes configuration, and makes it easier to manage complex applications.</p> <p>See this section of the docs for more details about the below examples.</p> <pre><code># nginx-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 2 # tells deployment to run 2 pods matching the template\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n</code></pre>"},{"location":"what_is_k8s/working_with_k8s/#helm-and-kustomize","title":"Helm and Kustomize","text":"<p>You'll probably come over Helm and Kustomize in your Kubernetes journey. While they are slightly more advanced topics, they are often super helpful, and worth mentioning here.</p> <p>Helm is a package manager for Kubernetes, which allows you to define, install, and manage applications on Kubernetes using charts. Charts are collections of Kubernetes manifests that describe an application, and can include templates, dependencies, and configuration options. Helm makes it easy to deploy complex applications, and manage their lifecycle. For example, to install Grafana on your cluster</p> <pre><code>helm repo add grafana https://grafana.github.io/helm-charts\nhelm repo update\nhelm install my-release grafana/grafana\n</code></pre> <p>Kustomize is a tool for customizing Kubernetes YAML configurations. It allows you to create overlays, which are modifications to existing Kubernetes manifests, without changing the original files. This is useful for managing different environments, such as development, staging, and production, without duplicating YAML files. In our app, we use Kustomize, though quite trivially.</p>"}]}